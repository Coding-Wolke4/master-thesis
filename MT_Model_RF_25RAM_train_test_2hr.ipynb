{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MT_Model-RF_25RAM_train_test_2hr.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nmqKh-4m9ZMS",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QvduQ3-09ima",
        "colab": {}
      },
      "source": [
        "%cd drive/My Drive/Master Thesis 2020"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r6dic0d89ks1",
        "colab": {}
      },
      "source": [
        "# !ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gLG01sGE9uI8",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import xlrd\n",
        "import copy\n",
        "import datetime\n",
        "import glob\n",
        "import time\n",
        "# from __future__ import division, print_function, unicode_literals\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns; sns.set()\n",
        "sns.set(style=\"white\")\n",
        "sns.set(style=\"whitegrid\", color_codes=True)\n",
        "\n",
        "# To plot pretty figures\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "# plt.rc(\"font\", size=14)\n",
        "# mpl.rc('axes', labelsize=14)\n",
        "# mpl.rc('xtick', labelsize=12)\n",
        "# mpl.rc('ytick', labelsize=12)\n",
        "%matplotlib inline\n",
        "\n",
        "# Ignore useless warnings (see SciPy issue #5998)\n",
        "import warnings\n",
        "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n_h8i8NbwFQi",
        "colab": {}
      },
      "source": [
        "# Reference\n",
        "# https://nbviewer.jupyter.org/github/ageron/handson-ml/blob/master/04_training_linear_models.ipynb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FRPe49GGuKPK"
      },
      "source": [
        "### Import data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NGUbAdzhuNau",
        "colab": {}
      },
      "source": [
        "df_uk = pd.read_csv('elexon_all_uk.csv', sep=',', parse_dates=True, index_col=[0], engine='python') # TO-DO: make sure the timeblokcs are continuous and with 30 min timeblocks\n",
        "df_uk = df_uk.rename(columns={'Unnamed: 0': 'timeblock'})\n",
        "df_uk.index.dtype # '<M8[ns]'is time series"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UFBc3fChYD94",
        "colab": {}
      },
      "source": [
        "df_uk.wind_elexon = pd.to_numeric(df_uk.wind_elexon, errors='coerce') # wind_elexon contains obejcts\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hXMmT5PRTy6h",
        "colab": {}
      },
      "source": [
        "df_uk.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K50j5xxf4KJ-",
        "colab_type": "text"
      },
      "source": [
        "### Add columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JZm65OEOvFb-",
        "colab": {}
      },
      "source": [
        "# Create new column y: intraday price - imbalance price >= 0  then denote as 1; intraday price - imbalance price <0 then denote as 0\n",
        "# TO-DO: ROC curve https://www.google.com/url?sa=i&url=https%3A%2F%2Fmachinelearningmastery.com%2Froc-curves-and-precision-recall-curves-for-classification-in-python%2F&psig=AOvVaw0v5zXIpH4HfiuTZ-tlMgrC&ust=1595149731542000&source=images&cd=vfe&ved=0CAIQjRxqFwoTCOCF0e-51uoCFQAAAAAdAAAAABAD\n",
        "# TO-DO: show how confident we should\n",
        "def create_y_column(row): # Alternative: where method\n",
        "    if row['intraday_price'] < row['imbalance_price']: # Learning: Use lambda function\n",
        "        val = 0\n",
        "    else:\n",
        "        val = 1\n",
        "\n",
        "    return val\n",
        "\n",
        "# Add y \n",
        "df_uk['y'] = df_uk.apply(create_y_column, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OpaVlRBPuplt",
        "colab": {}
      },
      "source": [
        "# Add error columns\n",
        "df_uk_error = df_uk.copy()\n",
        "\n",
        "df_uk_error['wind_entsoe_error'] = df_uk_error['wind_for_entsoe'] - df_uk_error['wind_entsoe']\n",
        "df_uk_error['wind_elexon_error'] = df_uk_error['wind_for_elexon'] - df_uk_error['wind_elexon']\n",
        "df_uk_error['solar_entsoe_error'] = df_uk_error['solar_for_entsoe'] - df_uk_error['solar_entsoe']\n",
        "# df_uk_error.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCFrT2Bw4KKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_uk = df_uk_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzB55VjDGti9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add weekday/weekend dummies\n",
        "df_uk['weekday'] = ((pd.DatetimeIndex(df_uk.index).dayofweek) // 5 == 1).astype(float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-1eSWZGyOoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add consin sin\n",
        "df_uk['timestamps'] = df_uk.index\n",
        "dateofyr = df_uk.timestamps.dt.dayofyear\n",
        "df_uk['timestamps_trigonometric'] = np.sin(dateofyr*2*np.pi/365)\n",
        "df_uk = df_uk.drop(columns='timestamps')\n",
        "# df_uk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EvKSsu_cocR1",
        "colab": {}
      },
      "source": [
        "# df_uk.head(72)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OHE21hbMfIF7",
        "colab": {}
      },
      "source": [
        "df_uk.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wu7sG2WSYrti"
      },
      "source": [
        "### Modeling - Random Forest\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eX84Xh0i3R8Z"
      },
      "source": [
        "##### Data prep (Full variables)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a8Mqg-Lr4nyo",
        "colab": {}
      },
      "source": [
        "df_uk_rf = df_uk.copy()\n",
        "df_uk_rf.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AO3QqcR4KKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set hyperparameters\n",
        "# Create time lag columns\n",
        "l = 672 # l is lag\n",
        "\n",
        "# Random Forest classifier parameters\n",
        "n_estimators = 500\n",
        "max_features = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3hYgM3ku0fPm",
        "colab": {}
      },
      "source": [
        "# Create t-2, t-3... columns\n",
        "\n",
        "###\n",
        "p = 6 # for lag 0.5 hr: 2 # for lag 2 hr: 6\n",
        "\n",
        "lags = range(p, p+l)  # 5 lags # 10 lags # 48 lags\n",
        "\n",
        "df_uk_rf = df_uk_rf.assign(**{ # Jeffrey: How does this work?\n",
        "    '{} (t-{})'.format(col, t): df_uk_rf[col].shift(t)\n",
        "    for t in lags\n",
        "    for col in df_uk_rf[['demand_INDO','demand_ITSDO']]\n",
        "})\n",
        "\n",
        "###\n",
        "p = 8  # for lag 0.5 hr: 4 # for lag 2 hr: 8\n",
        "\n",
        "lags = range(p, p+l) \n",
        "\n",
        "df_uk_rf = df_uk_rf.assign(**{ # Jeffrey: How does this work?\n",
        "    '{} (t-{})'.format(col, t): df_uk_rf[col].shift(t)\n",
        "    for t in lags\n",
        "    for col in df_uk_rf[['wind_entsoe', 'solar_entsoe', 'wind_elexon', 'wind_entsoe_error','solar_entsoe_error', 'wind_elexon_error']]\n",
        "})\n",
        "\n",
        "###\n",
        "p = 0 \n",
        "\n",
        "lags = range(p, p+l) \n",
        "\n",
        "df_uk_rf = df_uk_rf.assign(**{ # Jeffrey: How does this work?\n",
        "    '{} (t-{})'.format(col, t): df_uk_rf[col].shift(t)\n",
        "    for t in lags\n",
        "    for col in df_uk_rf[['wind_for_entsoe','solar_for_entsoe', 'wind_for_elexon', 'timestamps_trigonometric']]\n",
        "})\n",
        "\n",
        "\n",
        "###\n",
        "p = 7  # for lag 0.5 hr: 3 # for lag 2 hr: 7\n",
        "\n",
        "lags = range(p, p+l) \n",
        "\n",
        "df_uk_rf = df_uk_rf.assign(**{ # Jeffrey: How does this work?\n",
        "    '{} (t-{})'.format(col, t): df_uk_rf[col].shift(t)\n",
        "    for t in lags\n",
        "    for col in df_uk_rf[['imbalance_price','imbalance_volume', 'intraday_volume', 'intraday_price']]\n",
        "})\n",
        "df_uk_rf.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YVaBH4Yl4gN_",
        "colab": {}
      },
      "source": [
        "df_uk_rf = df_uk_rf.reindex(sorted(df_uk_rf.columns), axis=1) # No need to standardize the dataset for RF - Standardization gives the same result in RF\n",
        "df_uk_rf.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGIvbL-D4KLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check NA and extract the last value of the na's df\n",
        "df_na = df_uk_rf[df_uk_rf.isna().any(axis=1)].iloc[[-1]].index.to_frame()\n",
        "na_end = df_na.iloc[0,0]\n",
        "na_end"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W3A_TeFT4gOF",
        "colab": {}
      },
      "source": [
        "# Start the df with the first row with no NAs\n",
        "df_uk_rf = df_uk_rf.loc[na_end + datetime.timedelta(minutes=30): , :]\n",
        "df_uk_rf = df_uk_rf.drop(columns={'wind_for_entsoe','solar_for_entsoe', 'wind_for_elexon', 'timestamps_trigonometric',\n",
        "                                  'demand_INDO','demand_ITSDO', \n",
        "                                  'wind_entsoe','solar_entsoe', 'wind_elexon',\n",
        "                                  'wind_entsoe_error','solar_entsoe_error','wind_elexon_error',\n",
        "                                  'imbalance_price','imbalance_volume',\n",
        "                                  'intraday_volume', 'intraday_price',})\n",
        "df_uk_rf.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaLkOY484KLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_uk_rf[df_uk_rf.isnull().any(axis = 1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KnwyPOF4KLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the dataset into training, validationand testing set\n",
        "df_train = df_uk_rf['2017':'2018']\n",
        "df_vali = df_uk_rf['2019-01':]\n",
        "# df_test = df_uk_rf['2019-09':]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIBXaYYB4KLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df_train[df_train.isnull().any(axis = 1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yw915QDv4KLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df_vali[df_vali.isnull().any(axis = 1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vAlRLM9nEFDy",
        "colab": {}
      },
      "source": [
        "# df_test[df_test.isnull().any(axis = 1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZHD0Rut4KLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shuffle the rows # Need to shuffle before dividing x and y, otherwise they will not match\n",
        "df_train_shf = df_train.sample(frac=1) \n",
        "df_vali_shf = df_vali.sample(frac=1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdsTjs5d4KL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = df_train_shf.loc[:, df_train_shf.columns != 'y']\n",
        "train_labels = np.array(df_train_shf.pop('y')) \n",
        "\n",
        "vali = df_vali_shf.loc[:, df_vali_shf.columns != 'y']\n",
        "vali_labels = np.array(df_vali_shf.pop('y')) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bo9Lt5ykzRXM",
        "colab": {}
      },
      "source": [
        "features = list(train.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LEBG8m_Ix5IZ",
        "colab": {}
      },
      "source": [
        "# Validation\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "t0 = time.time()\n",
        "\n",
        "# Create the model\n",
        "model = RandomForestClassifier(n_estimators = n_estimators,  # this is # of trees\n",
        "                               bootstrap = True, \n",
        "                               max_features = max_features, random_state = 0) # levels:  5 to 7 -> 2^5, 2^7 = 128 # TO-DO: Where is the tree-pruning parameter? -> Try & error\n",
        "# Fit on training data\n",
        "model.fit(train, train_labels)\n",
        "\n",
        "t1 = time.time()\n",
        "\n",
        "total = t1-t0\n",
        "print(model)\n",
        "print('Run time(s)', str(datetime.timedelta(seconds=total)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zjABQu6zzm9Y",
        "colab": {}
      },
      "source": [
        "n_nodes = []\n",
        "max_depths = []\n",
        "\n",
        "# Stats about the trees in random forest\n",
        "for ind_tree in model.estimators_:\n",
        "    n_nodes.append(ind_tree.tree_.node_count) # try: 50 or 100 of trees\n",
        "    max_depths.append(ind_tree.tree_.max_depth) #  too deep is over-fitting 5-7 levels are already good\n",
        "    \n",
        "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
        "print(f'Average maximum depth {int(np.mean(max_depths))}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDiE11Evx8fW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot importance method 1\n",
        "feat_importances = pd.Series(model.feature_importances_, index=train.columns)\n",
        "feat_importances.nlargest(15).plot(kind='barh', color = 'royalblue')\n",
        "plt.tight_layout()\n",
        "filename = 'feature_importance_lag{}_ntrees{}_maxlevel{}_test'.format(l, n_estimators , max_features) # \n",
        "plt.savefig(filename+'.png')\n",
        "# Plot importance method 1# More colorss check here https://matplotlib.org/2.0.0/examples/color/named_colors.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMBrIQ5j7uac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot importance method 2 # Better -  easy to modify the plot # HELPPP: Wrong ytickes \n",
        "#https://stackoverflow.com/questions/332289/how-do-you-change-the-size-of-figures-drawn-with-matplotlib\n",
        "feat_importances = pd.Series(model.feature_importances_, index=train.columns)\n",
        "importances = feat_importances.nlargest(4)\n",
        "# importances = model.feature_importances_\n",
        "indices = np.argsort(importances)\n",
        "\n",
        "plt.title('Feature Importances')\n",
        "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
        "plt.xlabel('Relative Importance')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LEhSBF6ezuIg",
        "colab": {}
      },
      "source": [
        "# Training predictions (to demonstrate overfitting)\n",
        "train_rf_predictions = model.predict(train)\n",
        "train_rf_probs = model.predict_proba(train)[:, 1]\n",
        "\n",
        "# Testing predictions (to determine performance)\n",
        "rf_predictions = model.predict(vali)\n",
        "rf_probs = model.predict_proba(vali)[:, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYFvwJAHpL2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot formatting\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.rcParams['font.size'] = 18\n",
        "\n",
        "def evaluate_model(predictions, probs, train_predictions, train_probs):\n",
        "    \"\"\"Compare machine learning model to baseline performance.\n",
        "    Computes statistics and shows ROC curve.\"\"\"\n",
        "    \n",
        "    baseline = {}\n",
        "    \n",
        "    baseline['recall'] = recall_score(vali_labels, \n",
        "                                     [1 for _ in range(len(vali_labels))])\n",
        "    baseline['precision'] = precision_score(vali_labels, \n",
        "                                      [1 for _ in range(len(vali_labels))])\n",
        "    baseline['roc'] = 0.5\n",
        "    \n",
        "    results = {}\n",
        "    \n",
        "    results['recall'] = recall_score(vali_labels, predictions)\n",
        "    results['precision'] = precision_score(vali_labels, predictions)\n",
        "    results['roc'] = roc_auc_score(vali_labels, probs)\n",
        "    \n",
        "    train_results = {}\n",
        "    train_results['recall'] = recall_score(train_labels, train_predictions)\n",
        "    train_results['precision'] = precision_score(train_labels, train_predictions)\n",
        "    train_results['roc'] = roc_auc_score(train_labels, train_probs)\n",
        "    \n",
        "    for metric in ['recall', 'precision', 'roc']:\n",
        "        print(f'{metric.capitalize()} Baseline: {round(baseline[metric], 2)} Test: {round(results[metric], 2)} Train: {round(train_results[metric], 2)}')\n",
        "    \n",
        "    # Calculate false positive rates and true positive rates\n",
        "    base_fpr, base_tpr, _ = roc_curve(vali_labels, [1 for _ in range(len(vali_labels))])\n",
        "    model_fpr, model_tpr, _ = roc_curve(vali_labels, probs)\n",
        "\n",
        "    plt.figure(figsize = (8, 6))\n",
        "    plt.rcParams['font.size'] = 14\n",
        "    \n",
        "    # Plot both curves\n",
        "    plt.plot(base_fpr, base_tpr, 'b', label = 'baseline')\n",
        "    plt.plot(model_fpr, model_tpr, 'r', label = 'model')\n",
        "    plt.legend();\n",
        "    plt.xlabel('False Positive Rate'); \n",
        "    plt.ylabel('True Positive Rate'); plt.title('ROC Curves');\n",
        "    plt.show()\n",
        "\n",
        "evaluate_model(rf_predictions, rf_probs, train_rf_predictions, train_rf_probs)\n",
        "filename = 'roccurve_lag{}_ntrees{}_maxlevel{}'.format(l, n_estimators , max_features) # Jeffrey: can't print\n",
        "plt.savefig(filename+'.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KoRTIwYhzxt1",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Oranges):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    Source: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    # Plot the confusion matrix\n",
        "    plt.figure(figsize = (10, 10))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title, size = 22)\n",
        "    plt.colorbar(aspect=4)\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45, size = 14)\n",
        "    plt.yticks(tick_marks, classes, size = 14)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    \n",
        "    # Labeling the plot\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt), fontsize = 14,\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        \n",
        "    plt.grid(None)\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True Label', size = 14)\n",
        "    plt.xlabel('Predicted Label', size = 14)\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(vali_labels, rf_predictions)\n",
        "plot_confusion_matrix(cm, classes = ['ITP < SSP', 'ITP >= SSP'],\n",
        "                      title = 'Confusion Matrix')\n",
        "plt.tight_layout()\n",
        "filename = 'confmatrix_lag{}_ntrees{}_maxlevel{}'.format(l, n_estimators , max_features)\n",
        "plt.savefig(filename+'.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lSNjUie4KMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Confusion Matrix\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print('Confusion matrix', confusion_matrix(vali_labels, rf_predictions))\n",
        "\n",
        "# Accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('Accuracy score',accuracy_score(vali_labels, rf_predictions))\n",
        "\n",
        "# Recall\n",
        "from sklearn.metrics import recall_score\n",
        "print('Recall score', recall_score(vali_labels, rf_predictions, average=None))\n",
        "\n",
        "# Precision\n",
        "from sklearn.metrics import precision_score\n",
        "print('Precision score',precision_score(vali_labels, rf_predictions, average=None))\n",
        "\n",
        "# F1 score\n",
        "from sklearn.metrics import f1_score\n",
        "print('F1 score', f1_score(vali_labels, rf_predictions))\n",
        "# The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal. \n",
        "# The formula for the F1 score is: F1 = 2 * (precision * recall) / (precision + recall)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUGMD9h5EcT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}